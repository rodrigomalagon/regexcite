---
title: "word_extraction_example"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{word_extraction_example}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(regexcite)
```

# Word extraction: a **lorem ipsum** example

In this vignette we explore the functionality of `str_split_one` through the basic processing of a text generated by the package `stringi`. The objective of our workflow will be to extract a list of all the words mentioned in a text.

## Load and create sample text

We start by loading the heling package `stringi`, which contains the custom function `stri_rand_lipsum` to create "lorem ipsum" texts with a given number of paragraphs:

```{r}
#install.packages('stringi')
library(stringi)
number_paragraphs <- 10
(lorem <- stri_rand_lipsum(number_paragraphs))
```

For further processing, we now **collapse** the multiple paragraphs this text contains into a single string:

```{r}
(lorem <- paste(lorem,collapse=','))
```

Now we process this text to delete any punctuation and extract the words it contains:

```{r}
#Delete punctuation
pattern <- c(',','.','!')
for(str in pattern){
  lorem <- gsub(pattern = str, replace = '', lorem,fixed = TRUE)
}
lorem
```

This "processed" short text without punctuations is ready to be used by `str_split_one` and is stored in our `regexcite` package as a `.Rda` object. We thus extract the words from our sample text and finally clean duplicates

```{r}
words <- str_split_one(lorem,' ')
(words |> tolower() |> unique() -> unique_words)
```

We finally verify the data reduction:

```{r}
paste0('Number of words in text: ',length(words),'\nNumber of unique words in text: ',length(unique_words)) |> cat()
```
