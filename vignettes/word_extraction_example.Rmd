---
title: "word_extraction_example"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{word_extraction_example}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(regexcite)
```

# Word extraction: a **lorem ipsum** example

In this example we explore the functionality of `str_split_one` through the basic processing of a text generated by the package `stringi`. The objective of our workflow will be to extract a list of all the words mentioned in a given text.

## 1. Create sample text

We start by loading the helping package `stringi`, which contains the custom function `stri_rand_lipsum` to create "lorem ipsum" texts with a certain number of paragraphs:

```{r}
#install.packages('stringi')
library(stringi)
number_paragraphs <- 10
(lorem_sample <- stri_rand_lipsum(number_paragraphs))
```

For further processing, we now **collapse** the multiple paragraphs this text contains into a single string:

```{r}
(lorem_sample <- paste(lorem,collapse=','))
```

Now we process this text to delete any punctuation:

```{r}
#Delete punctuation
pattern <- c(',','.','!')
for(str in pattern){
  lorem_sample <- gsub(pattern = str, replace = '', lorem,fixed = TRUE)
}
lorem_sample
```

This "processed" short text without punctuation is ready to be used by `str_split_one` and is also stored in our `regexcite` package in the `lorem.rda` file.

## 2. Using data from the package

Now we proceed with the extraction of words from our sample text and clean the duplicated words. This sample text was saved in the `lorem.rda` file when developing this package. Therefore, we readily access our sample text created in the previous steps by calling `regexcite::lorem`:

```{r}
#Extract words
words <- str_split_one(regexcite::lorem,' ')
(words |> tolower() |> unique() -> unique_words)
```

We finally verify the data reduction:

```{r}
paste0('Number of words in text: ',length(words),'\nNumber of unique words in text: ',length(unique_words)) |> cat()
```

# External file processing

We finalize with the processing of strings using `str_split_one` in one external file containing a list of download paths for remote sensing imagery. This reference list comes from the [Maxar Open Data program](https://www.maxar.com/open-data) and is stored in our package inside the `csv/emilia_romagna_urls.csv` file.

This is a basic example to split a link and extract the date an image featuring a flooded area in Italy was captured:

```{r}
(file_link <- 'https://maxar-opendata.s3.us-west-2.amazonaws.com/events/Emilia-Romagna-Italy-flooding-may23/ard/32/120000301312/2021-05-20/10300100BF164000-visual.tif')
str_split_one(file_link,'/')[9]
```

We can apply this short process to the list of links within our file:

```{r}
# Load dataset
path_to_file <- system.file('csv/emilia_romagna_urls.csv',package = 'regexcite')

# Extract urls as character vector
urls <- read.csv(path_to_file)[[1]]
         
# Extract info with str_split_one
lapply(urls,function(url){str_split_one(url,'/')[8]}) |> unlist() -> QUAD_key
lapply(urls,function(url){str_split_one(url,'/')[9]}) |> unlist() -> dates

# Construct dataframe
(df <- data.frame(date = dates,QUAD_key = QUAD_key,url = urls))
```
